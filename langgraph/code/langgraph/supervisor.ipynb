{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d9dfd4-d47a-49ae-95ec-049c6340fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = 'sk-a31a563bce7146bf8c8ab93ad5fea537'\n",
    "os.environ[\"TAVILY_API_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2edf1c29-582b-4dbe-9343-a0ade6281343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_result=5)\n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54f01f0f-c838-4efe-813e-539a767bc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    print('--------------------')\n",
    "    print(result)\n",
    "    print('********************')\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result['messages'][-1].content, name=name)]\n",
    "        # \"messages\": result['messages']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a362b22d-1ec1-4c9c-a0a0-99f1bb8a8823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "members = ['Researcher', 'Coder']\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    "    \" Given the conversation below, who should act next?\"\n",
    "    \" Or should we FINISH? Select one of: {options}\"\n",
    ")\n",
    "options = ['FINISH'] + members\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name='messages')\n",
    "    ]\n",
    ").partial(options=str(options), members=','.join(members))\n",
    "\n",
    "# 使用 Qwen 模型\n",
    "qwen_llm = ChatTongyi(\n",
    "    model=\"qwen-max\",              # Qwen 模型名称，例如 \"qwen-7b\" 或 \"qwen-14b\"\n",
    "    api_key=\"sk-a31a563bce7146bf8c8ab93ad5fea537\"   # 替换为实际的 API 密钥\n",
    ")\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = prompt | qwen_llm.with_structured_output(routeResponse)\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15dfec64-067c-4e5b-b340-4922413ed3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f1eb33b3e90>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "research_agent = create_react_agent(qwen_llm, tools=[tavily_tool])\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "code_agent = create_react_agent(qwen_llm, tools=[python_repl_tool])\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "60a164f0-c8fa-4a2c-b9a1-1a839b3ec452",
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    workflow.add_edge(member, 'supervisor')\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map['FINISH'] = END\n",
    "workflow.add_conditional_edges('supervisor', lambda x: x['next'], conditional_map)\n",
    "workflow.add_edge(START, 'supervisor')\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0f6a52d-4f70-4927-9ac0-afc7612eece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "{'messages': [HumanMessage(content='Code hello world and print it to the terminal', additional_kwargs={}, response_metadata={}, id='62f51810-2cb4-45e0-9b79-4223c0e0ba3f', role='user'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'name': 'Python_REPL', 'arguments': '{\"query\": \"print(\\'Hello, world!\\')\"}'}, 'index': 0, 'id': 'call_1f55addafa0c43989935c9', 'type': 'function'}]}, response_metadata={'model_name': 'qwen-max', 'finish_reason': 'tool_calls', 'request_id': '5800608b-077f-928d-9c18-be3ed6f26aff', 'token_usage': {'input_tokens': 205, 'output_tokens': 24, 'total_tokens': 229}}, id='run-ba0f2b7a-3554-4b92-8bfa-e9cd6e6144d9-0', tool_calls=[{'name': 'Python_REPL', 'args': {'query': \"print('Hello, world!')\"}, 'id': 'call_1f55addafa0c43989935c9', 'type': 'tool_call'}]), ToolMessage(content='Hello, world!\\n', name='Python_REPL', id='e3e84f93-e861-44a2-b7bb-20d27b391ebc', tool_call_id='call_1f55addafa0c43989935c9'), AIMessage(content='The message \"Hello, world!\" has been printed to the terminal.', additional_kwargs={}, response_metadata={'model_name': 'qwen-max', 'finish_reason': 'stop', 'request_id': '4e1d10de-ccb2-9fbb-820f-2e0e75ba7b6a', 'token_usage': {'input_tokens': 240, 'output_tokens': 15, 'total_tokens': 255}}, id='run-91cb91cf-ccde-426d-8cea-59ba8d1c16b0-0')]}\n",
      "********************\n",
      "{'messages': [HumanMessage(content='Code hello world and print it to the terminal', additional_kwargs={}, response_metadata={}, id='62f51810-2cb4-45e0-9b79-4223c0e0ba3f', role='user'), HumanMessage(content='The message \"Hello, world!\" has been printed to the terminal.', additional_kwargs={}, response_metadata={}, name='Coder')], 'next': 'FINISH'}\n"
     ]
    }
   ],
   "source": [
    "# for s in graph.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             HumanMessage(content=\"Code hello world and print it to the terminal\")\n",
    "#         ]\n",
    "#     }\n",
    "# ):\n",
    "#     if \"__end__\" not in s:\n",
    "#         print(s)\n",
    "#         print(\"----\")\n",
    "\n",
    "res = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Code hello world and print it to the terminal\", role='user')\n",
    "            # \"Code hello world and print it to the terminal\"\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418e5ff-ba51-4d04-b2f8-49a5623eb049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
