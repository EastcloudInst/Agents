{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8647336-8765-4be2-a64d-0446ee983d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e096f2c3-16e1-4c24-8914-b6e08a0a7493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好！当然可以。量子计算是一种基于量子力学原理的新型计算方式，它与传统的基于二进制的经典计算有着根本的不同。在经典计算机中，信息的基本单位是比特（bit），它可以表示0或1两种状态之一。而在量子计算中，信息的基本单位叫做量子比特（qubit）。量子比特利用了量子力学中的叠加态和纠缠等特性，使得一个量子比特不仅可以表示0或1，还可以同时处于这两种状态的任意线性组合之中。这种性质让量子计算机在处理某些特定问题时比传统计算机更加高效。\\n\\n### 量子计算的关键概念\\n\\n- **叠加**：这是指量子系统能够同时存在于多个状态之中。对于一个量子比特来说，这意味着它可以同时代表0和1。\\n- **纠缠**：当两个或更多的量子比特以一种特殊的方式相互作用后，它们之间就会形成纠缠关系。即使相隔很远，对其中一个量子比特的操作也会立即影响到另一个量子比特的状态。\\n- **干涉**：通过精确地控制量子比特之间的相互作用，可以使不同的路径之间发生建设性或者破坏性的干涉，从而提高正确答案的概率而减少错误答案出现的可能性。\\n\\n### 应用领域\\n\\n量子计算因其独特的性质，在解决某些类型的问题上具有潜在优势，比如：\\n- 大整数分解：这对于当前广泛使用的加密算法构成了挑战。\\n- 模拟量子系统：有助于新材料、药物的设计等领域。\\n- 优化问题：如物流规划、金融建模等复杂优化场景。\\n\\n### 当前状态与发展\\n\\n尽管量子计算理论已经相当成熟，并且实验室里也成功构建了一些小型量子计算机原型机，但要实现大规模实用化的量子计算机仍然面临许多技术难题。包括但不限于如何长时间保持量子态的稳定性（即克服退相干问题）、如何有效地扩展量子比特数量以及开发适合量子硬件运行的新算法等等。\\n\\n总之，量子计算是一个非常前沿且快速发展的领域，虽然距离真正普及还有一定距离，但它展现出了解决未来一些重大科学和技术挑战的巨大潜力。' additional_kwargs={} response_metadata={'model_name': 'qwen-max', 'finish_reason': 'stop', 'request_id': '4051fb2a-069d-9f2c-9075-dc6702678a06', 'token_usage': {'input_tokens': 16, 'output_tokens': 418, 'total_tokens': 434}} id='run-66dd8040-6487-4bd7-9ce8-e926b0e49947-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "\n",
    "# 使用 Qwen 模型\n",
    "qwen_llm = ChatTongyi(\n",
    "    model=\"qwen-max\",              # Qwen 模型名称，例如 \"qwen-7b\" 或 \"qwen-14b\"\n",
    "    api_key=\"sk-a31a563bce7146bf8c8ab93ad5fea537\"   # 替换为实际的 API 密钥\n",
    ")\n",
    "\n",
    "# 调用 Qwen 模型\n",
    "response = qwen_llm.invoke(\"你好！能介绍一下量子计算吗？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b2b853-615e-4b3d-a33c-f0a385aafcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "import getpass \n",
    "import os \n",
    "\n",
    "# def _set_env(var: str): \n",
    "#     if not os.environ.get(var): \n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \") \n",
    "\n",
    "# # api key: sk-a31a563bce7146bf8c8ab93ad5fea537\n",
    "# _set_env(\"DASHSCOPE_API_KEY\")\n",
    "\n",
    "# llm = Tongyi()\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [qwen_llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e6c61e-4bc0-446d-9834-c8996f2ac68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9330d1b-58a6-4eca-abfd-18cdd4978298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "def invoke_graph_(user_input: str):\n",
    "    answers = graph.invoke({\"messages\": [(\"user\", user_input)]})\n",
    "    print(answers)\n",
    "\n",
    "while True:\n",
    "    # try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # stream_graph_updates(user_input)\n",
    "        invoke_graph_(user_input)\n",
    "    \n",
    "    # except:\n",
    "    #     # fallback if input() is not available\n",
    "    #     user_input = \"What do you know about LangGraph?\"\n",
    "    #     print(\"User: \" + user_input)\n",
    "    #     stream_graph_updates(user_input)\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c53217d-7edc-4d7c-98fa-42e2e3f4465e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['456']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StateTest(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "stateTest: StateTest = {\n",
    "    'messages': ['123']\n",
    "}\n",
    "\n",
    "stateTest['messages'] = ['456']\n",
    "\n",
    "stateTest['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de27e2fe-3ee6-4207-8a37-efdf1f973786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [0.5, 0.75]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': [0.5, 0.75]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "def reducer(a: list, b: int | None) -> list:\n",
    "    if b is not None:\n",
    "        return a + [b]\n",
    "    return a\n",
    "\n",
    "class State(TypedDict):\n",
    "    x: Annotated[list, reducer]\n",
    "\n",
    "class ConfigSchema(TypedDict):\n",
    "    r: float\n",
    "\n",
    "graph = StateGraph(State, config_schema=ConfigSchema)\n",
    "\n",
    "def node(state: State, config: RunnableConfig) -> dict:\n",
    "    r = config[\"configurable\"].get(\"r\", 1.0)\n",
    "    x = state[\"x\"][-1]\n",
    "    next_value = x * r * (1 - x)\n",
    "    return {\"x\": next_value}\n",
    "\n",
    "graph.add_node(\"A\", node)\n",
    "graph.set_entry_point(\"A\")\n",
    "graph.set_finish_point(\"A\")\n",
    "compiled = graph.compile(checkpointer=memory)\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "\n",
    "step1 = compiled.invoke({\"x\": 0.5}, {\"configurable\": {\"r\": 3.0, \"thread_id\": \"1\"}})\n",
    "print(step1)\n",
    "{'x': [0.5, 0.75]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a452b293-cda5-4ef6-a646-cc80f60f26bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [0.5, 0.75, 0.6, 0.72]}\n"
     ]
    }
   ],
   "source": [
    "step1 = compiled.invoke({\"x\": 0.6}, {\"configurable\": {\"r\": 3.0, \"thread_id\": \"1\"}})\n",
    "print(step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f994880-80b2-40b0-84d2-394e9f751c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "if messages := []:\n",
    "    print(\"[]\")\n",
    "else:\n",
    "    print(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b0ad25-ca17-4a5a-8819-243f98fcc2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'name': 'GetMoney', 'arguments': '{\"Money\": \"San Francisco, CA\"}'}, 'index': 0, 'id': 'call_65338a678da545f3a03ae5', 'type': 'function'}]}, response_metadata={'model_name': 'qwen-max', 'finish_reason': 'tool_calls', 'request_id': '76eca852-ad9d-9773-b55b-d139d8cceb6c', 'token_usage': {'input_tokens': 252, 'output_tokens': 20, 'total_tokens': 272}}, id='run-21383236-5056-4a55-a1f0-586de827fb29-0', tool_calls=[{'name': 'GetMoney', 'args': {'Money': 'San Francisco, CA'}, 'id': 'call_65338a678da545f3a03ae5', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class GetWeather(BaseModel):\n",
    "    '''Get the current weather in a given location'''\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "class GetPrice(BaseModel):\n",
    "    '''Get the price of a specific product.'''\n",
    "\n",
    "    product: str = Field(..., description=\"The product to look up.\")\n",
    "\n",
    "\n",
    "# 使用 Qwen 模型\n",
    "llm = ChatTongyi(\n",
    "    model=\"qwen-max\",              # Qwen 模型名称，例如 \"qwen-7b\" 或 \"qwen-14b\"\n",
    "    api_key=\"sk-a31a563bce7146bf8c8ab93ad5fea537\"   # 替换为实际的 API 密钥\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([GetWeather, GetPrice])\n",
    "llm_with_tools.invoke(\"what is the weather like in San Francisco\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38920ade-f1bf-4c7f-873b-6b57f33dd7e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca3d5d-8054-47c9-be09-1652d9b0fd85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
